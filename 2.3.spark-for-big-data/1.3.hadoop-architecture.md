# ğŸ— **Hadoop Architecture - Core Components & Execution Workflow**

Understanding **Hadoopâ€™s execution workflow** is essential to see **how data flows through the system**. Hadoop follows a **Master-Slave architecture**, where the **Master nodes** manage the system, and the **Slave nodes** execute tasks.

Hadoop processing can be divided into **two main scenarios**:

- 1ï¸âƒ£ **Storage Workflow** (When a file is stored in HDFS)
- 2ï¸âƒ£ **Batch Processing Workflow** (When a user runs a query or submits a job)

---

<div style="display: flex; justify-content: center; align-items: center;">
    <img alt="Hadoop Architecture" src="images/hadoop-architecture.png" />
</div>

---

## ğŸ”¥ **Hadoop Architecture - The Big Picture**

```mermaid
graph TD
  A[ğŸ‘¤ User/ğŸ’» HDFS Client]

  subgraph X[Hadoop Master Nodes]
    direction TB
    B[ğŸ External Tools - Hive, Pig, HBase, Spark]
    C[ğŸ› ResourceManager - YARN]
    D[ğŸ§  NameNode - HDFS]
    E[ğŸ“œ Secondary NameNode - HDFS]
    F[ğŸ“ ApplicationMaster - YARN]
    G[ğŸ§  JobTracker - MapReduce]
  end

  subgraph Z[Hadoop Slave Nodes]
    direction TB
    H[ğŸ’¾ DataNodes - HDFS]
    I[ğŸ–¥ï¸ NodeManagers - YARN]
    J[ğŸ”„ TaskTrackers - MapReduce]
  end


  A --> X --> Z

```

### **ğŸ“Œ Detailed Explanation:**

1. **Master Nodes**:

   - **NameNode (ğŸ§ )**: Manages metadata about the file system and locations of data blocks.
   - **Secondary NameNode (ğŸ“œ)**: Takes periodic snapshots of the NameNode's metadata but does not serve as a backup.
   - **ResourceManager (ğŸ›)**: Central YARN component that allocates resources and manages the execution of distributed applications.
   - **ApplicationMaster (ğŸ“)**: Manages the lifecycle of applications, negotiates resources, and oversees task execution.
   - **External Tools (ğŸ)**: Tools like Hive (for SQL processing), Pig (for scripting), and HBase (for NoSQL database) interact with the Hadoop ecosystem to provide additional functionality.

2. **Slave Nodes**:
   - **DataNodes (ğŸ’¾)**: Store the actual data blocks. Handle read and write requests from clients and perform block replication.
   - **NodeManagers (ğŸ–¥ï¸)**: Run tasks on worker nodes and report resource usage to the ResourceManager.
   - **TaskTrackers (ğŸ”„)**: Execute individual tasks assigned by the MapReduce JobTracker.

### **ğŸ“Œ Key Components:**

#### **HDFS Components**

- **NameNode (ğŸ§ )**: Manages metadata and file locations in HDFS.
- **DataNode (ğŸ’¾)**: Stores actual data blocks in HDFS.
- **Secondary NameNode (ğŸ“œ)**: Takes periodic snapshots of the NameNode's metadata.

#### **MapReduce Components**

- **JobTracker**: Manages job scheduling and task assignment (not shown in the diagram).
- **TaskTracker (ğŸ”„)**: Executes tasks assigned by the JobTracker.

#### **YARN Components**

- **ResourceManager (ğŸ›)**: Allocates resources and manages the execution of distributed applications.
- **NodeManager (ğŸ–¥ï¸)**: Manages resources and application containers on each node.
- **ApplicationMaster (ğŸ“)**: Manages the lifecycle of applications, including resource negotiation and task execution.

## ğŸ“‚ **Storage Workflow in HDFS (Step-by-Step)**

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ User
    participant HDFSClient as ğŸ—„ï¸ HDFS Client (Master)
    participant NameNode as ğŸ§  NameNode - Metadata (Master)
    participant DataNode1 as ğŸ’¾ DataNode 1 (Slave)
    participant DataNode2 as ğŸ’¾ DataNode 2 (Slave)
    participant DataNode3 as ğŸ’¾ DataNode 3 (Slave)

    User->>HDFSClient: Upload file "bigdata.log" (300MB)
    HDFSClient->>HDFSClient: Split file into 128MB, 128MB, and 44MB blocks
    HDFSClient->>NameNode: Request block storage locations
    NameNode->>HDFSClient: Assign DataNodes for each block

    HDFSClient->>DataNode1: Store Block 1 (128MB)
    HDFSClient->>DataNode2: Store Block 2 (128MB)
    HDFSClient->>DataNode3: Store Block 3 (44MB)

    DataNode1->>NameNode: Report "Block 1 stored"
    DataNode2->>NameNode: Report "Block 2 stored"
    DataNode3->>NameNode: Report "Block 3 stored"

    NameNode->>User: File successfully stored in HDFS!
```

ğŸ“Œ **Explanation:**

- 1ï¸âƒ£ The **HDFS Client** splits large files into blocks.
- 2ï¸âƒ£ The **NameNode (Master)** assigns DataNodes for storage.
- 3ï¸âƒ£ **DataNodes (Slaves)** store the actual data blocks.
- 4ï¸âƒ£ The **NameNode tracks the metadata** (which block is stored where).

ğŸ’¡ **HDFS ensures data redundancy by replicating blocks across multiple nodes.**

---

## ğŸ— **Batch Processing Workflow in Hadoop (Step-by-Step)**

```mermaid
sequenceDiagram
    participant ğŸ‘¤ User
    participant ğŸ ExternalTools (Master)
    participant ğŸ› ResourceManager (Master)
    participant ğŸ“ ApplicationMaster (Master)
    participant ğŸ–¥ï¸ NodeManager (Slave)
    participant ğŸ”„ TaskTracker (Slave)
    participant ğŸ’¾ DataNode (Slave)

    note over ğŸ‘¤ User: Submits job/query
    ğŸ‘¤ User->>ğŸ ExternalTools (Master): Submit query (e.g., Hive, Pig)
    note over ğŸ ExternalTools (Master): Converts query to job
    ğŸ ExternalTools (Master)->>ğŸ› ResourceManager (Master): Request resources for job
    note over ğŸ› ResourceManager (Master): Allocates resources
    ğŸ› ResourceManager (Master)-->>ğŸ ExternalTools (Master): Resources allocated
    ğŸ ExternalTools (Master)->>ğŸ“ ApplicationMaster (Master): Submit application
    note over ğŸ“ ApplicationMaster (Master): Manages application lifecycle
    ğŸ“ ApplicationMaster (Master)->>ğŸ› ResourceManager (Master): Negotiate resources
    ğŸ› ResourceManager (Master)-->>ğŸ“ ApplicationMaster (Master): Allocate containers
    ğŸ“ ApplicationMaster (Master)->>ğŸ–¥ï¸ NodeManager (Slave): Request container launch
    note over ğŸ–¥ï¸ NodeManager (Slave): Launches containers
    ğŸ–¥ï¸ NodeManager (Slave)-->>ğŸ“ ApplicationMaster (Master): Container launched

    note over ğŸ“ ApplicationMaster (Master): Assigns tasks to TaskTracker
    ğŸ“ ApplicationMaster (Master)->>ğŸ”„ TaskTracker (Slave): Assign tasks
    ğŸ”„ TaskTracker (Slave)->>ğŸ’¾ DataNode (Slave): Process data blocks
    note over ğŸ’¾ DataNode (Slave): Provides data blocks to TaskTracker
    ğŸ’¾ DataNode (Slave)-->>ğŸ”„ TaskTracker (Slave): Provide data blocks
    ğŸ”„ TaskTracker (Slave)-->>ğŸ“ ApplicationMaster (Master): Task completion status
    note over ğŸ“ ApplicationMaster (Master): Monitors task completion
    ğŸ“ ApplicationMaster (Master)-->>ğŸ ExternalTools (Master): Job completion status
    ğŸ ExternalTools (Master)-->>ğŸ‘¤ User: Query results
```

### **Processing Workflow (Master/Slave)**

1. **User (ğŸ‘¤)**: Submits a job or query through external tools like Hive or Pig.
2. **External Tools (Master) (ğŸ)**: Convert the query into a job and request resources from the ResourceManager.
3. **ResourceManager (Master) (ğŸ›)**: Allocates resources and informs the External Tools.
4. **External Tools (Master) (ğŸ)**: Submit the application to the ApplicationMaster.
5. **ApplicationMaster (Master) (ğŸ“)**: Manages the application's lifecycle, negotiates resources, and requests container launch from NodeManagers.
6. **NodeManager (Slave) (ğŸ–¥ï¸)**: Launches the containers and informs the ApplicationMaster.
7. **ApplicationMaster (Master) (ğŸ“)**: Assigns tasks to TaskTrackers.
8. **TaskTracker (Slave) (ğŸ”„)**: Processes data blocks by interacting with DataNodes and provides the task completion status to the ApplicationMaster.
9. **ApplicationMaster (Master) (ğŸ“)**: Provides the job completion status to the External Tools.
10. **External Tools (Master) (ğŸ)**: Return the query results to the User.
